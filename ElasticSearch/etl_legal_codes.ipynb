{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading to docker image of ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl_script import *\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes_folder = \"../ReadFiles/Codigos\"\n",
    "\n",
    "codes, entries = get_files(codes_folder, return_entries=True)\n",
    "\n",
    "c = 0\n",
    "for code, entry in zip(codes,entries):\n",
    "    if c < 2:\n",
    "        print(entry, '|', code[0])\n",
    "        print(code[1:3])\n",
    "        print(\"\\n-------------------------------\\n\")\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID of legal sources\n",
    "\n",
    "The ID of every legal source (codes, statutes, norms) are storage on the csv file \"codes_id\". The ID were made \"by hand\" in order to improve the human reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "codesid_folder = \"../ReadFiles/codes_id.csv\"\n",
    "\n",
    "codesid_path = os.path.abspath(codesid_folder)\n",
    "with open(codesid_path, 'r', encoding='utf-8-sig') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    codes_id = {}\n",
    "    for row in csv_reader:\n",
    "        codes_id[row[0]] = row[1]\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "# codes_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New hierarchy\n",
    "\n",
    "This hierarchy was made according to observed on the research "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy = {\n",
    "    # Agregados\n",
    "    'LIBRO': 'book',\n",
    "    'PARTE': 'part',\n",
    "    \n",
    "    # Original\n",
    "    'TITULO' : 'headline',\n",
    "    'DISPOSICIONES' : 'headline',\n",
    "    'CAPITULO' : 'chapter',\n",
    "    \n",
    "    # Agregado\n",
    "    'SECCION': 'section',\n",
    "    \n",
    "    #Original\n",
    "    'ARTICULO' : 'article',\n",
    "    \n",
    "    # Agregados\n",
    "    'CONSIDERANDO' : 'article',\n",
    "    'PREAMBULO' : 'article',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look the content of the every legal source\n",
    "\n",
    "Here you will find the ammount of each hierarchy that every file has on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show_codes_content(codes, entries, hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the evolution of every change in model.\n",
    "\n",
    "For the embeddings model, a delimitation by dots and dot-comma was made. Here you can see the evolution on the quantity of elements for each interation by passing a True value on \"show_difference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_json_files(codes, entries, codes_id, show_difference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"http://localhost:9200/test_all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading to docker\n",
    "## Delete on case of emergency\n",
    "\n",
    "During our development, the cases of overloading were common. Eviting to have more articles than the needed, a delete process was stablished on the beginning. If you need it, just uncomment the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.delete(main_url)\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "\n",
    "Gives the structure of each document to Elastic Search. Like initializing a Data Base on SQL, the elements on the doc needs to respect the value set on the mapping.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping.json', 'r') as json_file:\n",
    "    mapping = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    response = requests.put(main_url, json=mapping)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check mapping\n",
    "\n",
    "Just a revision that everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(main_url)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of embedds vector\n",
    "\n",
    "This is where the ML magic begings. Don't worry, it takes a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastparquet import ParquetFile\n",
    "\n",
    "pf = ParquetFile('cons_codes.parq')\n",
    "\n",
    "df = pf.to_pandas()\n",
    "df = df[['id', 'embedds']]\n",
    "\n",
    "embedds = df['embedds'].tolist()\n",
    "ids = df['id'].tolist()\n",
    "\n",
    "embeddings = {}\n",
    "for art_id, embedd in zip(ids, embedds):\n",
    "    embeddings[art_id] = embedd\n",
    "    \n",
    "# embeddings['336transporte00000201000001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loadding\n",
    "\n",
    "If you want to see the process, go to etl_script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes_folder = \"../ReadFiles/Embeddings\"\n",
    "load_to_es_docker(codes_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting of total values at the docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_docs = f\"{main_url}/_count?q=*\"\n",
    "count_test = requests.get(count_docs)\n",
    "\n",
    "result = json.loads(count_test.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to Elastic Search\n",
    "## Simple Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_test = f\"{main_url}/_search\"\n",
    "query_test = {\n",
    "    \"query\": {\n",
    "        \"simple_query_string\": {\n",
    "            \"query\": \"constitucion\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "query_test = requests.get(local_test, json=query_test)\n",
    "\n",
    "result = json.loads(query_test.text)\n",
    "print(result)\n",
    "print(result['hits']['total']['value'])\n",
    "print(result['hits']['max_score'])\n",
    "best_rated = result['hits']['hits'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow + ElasticSearch = Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow_hub\n",
    "!pip3 install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_model import embed_text\n",
    "import requests\n",
    "\n",
    "local_test = \"http://localhost:9200/test_all/_search\"\n",
    "query = \"adolescencia\"\n",
    "\n",
    "query_vector = embed_text(query)\n",
    "\n",
    "query_test = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "      },\n",
    "      \"script\": {\n",
    "        \"source\": \"cosineSimilarity(params.queryVector, doc['embedds'])\",\n",
    "        \"params\": {\n",
    "          \"queryVector\": query_vector\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "query_test = requests.get(local_test, json=query_test)\n",
    "result = json.loads(query_test.text)\n",
    "print(result['hits']['total']['value'])\n",
    "print(result['hits']['max_score'])\n",
    "best_rated = result['hits']['hits'][1]\n",
    "best_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "julynter-results": {
   "filteredId": [],
   "filteredIndividual": [],
   "filteredRestart": [],
   "filteredType": [],
   "hash": "a4e87858d0c493eb3405ac3f46798361c7a6c49d",
   "visible": [
    {
     "cellId": "group",
     "hash": "19d3d3d153f22e318cbe061df9e685ba5165b0aa",
     "reason": "This groups other lint messages",
     "reportId": "group",
     "reportType": "confusenotebook",
     "suggestion": null,
     "text": "Confuse Notebook"
    },
    {
     "cellId": 28,
     "hash": "eead6b466817837f23b03a864f066a085955905f",
     "reason": "A markdown cell at the end of the notebook can conclude it, presenting a summary of the obtained results.",
     "reportId": "c5",
     "reportType": "confusenotebook",
     "suggestion": "Please consider adding a markdown cell to conclude the notebook.",
     "text": "The last cell of the notebook is not a markdown cell"
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
